# Change OUTPUT_DIR as appropriate for production
OUTPUT_DIR=/tmp/

WALTERS_ART_MUSEUEM_KEY=not_set
BROOKLYN_MUSEUM_API_KEY=not_set
DATA_GOV_API_KEY=not_set
EUROPEANA_API_KEY=not_set
FLICKR_API_KEY=not_set
NYPL_API_KEY=not-set
THINGIVERSE_TOKEN=not_set
WM_SCRIPT_CONTACT=data-engineering@creativecommons.org

S3_BUCKET=not_set
AWS_ACCESS_KEY=test_key
AWS_SECRET_KEY=test_secret
TEST_ACCESS_KEY=test_key
TEST_SECRET_KEY=test_secret

# Change the following line in prod to use the appropriate DB
AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
AIRFLOW__CORE__EXECUTOR=LocalExecutor
AIRFLOW__CORE__LOAD_EXAMPLES=False

# Uncomment the following line and set a Fernet key in prod using the output of
# python -c "import base64, os; print(base64.urlsafe_b64encode(os.urandom(32)).decode())"
# AIRFLOW__CORE__FERNET_KEY=

# Change the following line in prod to use the appropriate DB
AIRFLOW_CONN_POSTGRES_OPENLEDGER_UPSTREAM=postgres://deploy:deploy@postgres:5432/openledger
AIRFLOW_CONN_POSTGRES_OPENLEDGER_TESTING=postgres://deploy:deploy@postgres:5432/openledger

OPENLEDGER_CONN_ID=postgres_openledger_upstream
TEST_CONN_ID=postgres_openledger_testing

S3_LOCAL_ENDPOINT=http://s3:5000
AIRFLOW_CONN_AWS_PROD=aws://test_key:test_secret@?region_name=us-east-1&host=http://s3:5000
AIRFLOW_CONN_AWS_TEST=aws://test_key:test_secret@?region_name=us-east-1&host=http://s3:5000

AWS_CONN_ID=aws_prod
AWS_TEST_CONN_ID=aws_test

AIRFLOW_CONN_EMR_EMPTY=emr://
AIRFLOW_CONN_EMR_TEST=emr://?host=http://s3:5000

EMR_CONN_ID=emr_empty
EMR_TEST_CONN_ID=emr_test

CCCATALOG_STORAGE_BUCKET=cccatalog-storage

AIRFLOW_PORT=9090
LOADER_FILE_AGE=1
